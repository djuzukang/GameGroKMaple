from ultralytics import YOLO
import os
from pathlib import Path
import subprocess
import threading


# âœ… TensorBoard ìë™ ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)
def launch_tensorboard(logdir='runs/detect', port=6006):
    def _run():
        subprocess.run(["tensorboard", "--logdir", logdir, f"--port={port}"])
    threading.Thread(target=_run, daemon=True).start()
    print(f"[ğŸ”] TensorBoard launched at http://localhost:{port}")

# âœ… í•™ìŠµ ì‹¤í–‰
def train_yolo():
    model = YOLO("yolov8s.pt")  # ë˜ëŠ” yolov8n.pt, yolov8m.pt, yolov8l.pt ë“± ë³€ê²½ ê°€ëŠ¥
    model.train(
        data="data.yaml",         # data.yaml ê²½ë¡œ
        epochs=50,               # ì—í­ ìˆ˜ (ë¡œì»¬ì€ 100 ì¶”ì²œ, í° í™˜ê²½ì—ì„œëŠ” ì¦ê°€ ê°€ëŠ¥)
        imgsz=640,                # ì´ë¯¸ì§€ ì…ë ¥ í¬ê¸° (YOLOëŠ” ì •ì‚¬ê°í˜•ìœ¼ë¡œ resize)
        batch=32,                 # ë¡œì»¬ GPUì— ë§ì¶˜ ë°°ì¹˜ ì‚¬ì´ì¦ˆ
        name="nunu_elna_exp1",    # ê²°ê³¼ ì €ì¥ í´ë” ì´ë¦„ (runs/detect/nunu_elna_exp1)
        project='runs/detect',    # runs/detect/exp1 êµ¬ì¡° ì¤‘ ìƒìœ„ í´ë”ë¥¼ ì§€ì •, ê¸°ë³¸ê°’ì€ runs/train
        # device=0,                 # 0ë²ˆ GPU ì‚¬ìš©
        # workers=8,                # ë°ì´í„° ë¡œë”© ë³‘ë ¬ ì‘ì—… ìˆ˜ (RAM 32GBë©´ ì—¬ìœ  ìˆìŒ)
        verbose=True
    )


# âœ… fine-tuning ì‹¤í–‰ í•¨ìˆ˜ (player_dot ì „ìš©)
def fine_tune_yolo():
    model = YOLO("yolov8s.pt")  # ë˜ëŠ” yolov8n.pt, yolov8m.pt, yolov8l.pt ë“± ë³€ê²½ ê°€ëŠ¥
    model.train(
        data="player_dot_finetune.yaml",
        epochs=50,
        imgsz=320,
        batch=32,
        name="player_dot_finetune",
        project="runs/fine_tune",
        verbose=True
    )


if __name__ == '__main__':
    # ğŸ¯ ë¡œê·¸ ë””ë ‰í† ë¦¬ ì„¤ì • ë° TensorBoard ì‹¤í–‰
    logdir = Path('runs/detect')
    if not logdir.exists():
        logdir.mkdir(parents=True, exist_ok=True)

    launch_tensorboard(logdir=str(logdir))
    # train_yolo()
    fine_tune_yolo()

    # âš ï¸ ê°•í™”í•™ìŠµìš© í™˜ê²½ì—ì„œ YOLOëŠ” ê°ì²´ ì¸ì‹ë§Œ ìˆ˜í–‰í•˜ê³ 
    # ì´í›„ í–‰ë™(í‚¤ì…ë ¥, í´ë¦­ ë“±)ì€ DQN ëª¨ë¸ì´ ê²°ì •í•©ë‹ˆë‹¤.
    # ì•„ë˜ ì¶”ë¡  í•¨ìˆ˜ë“¤ì€ ì‹¤ì‚¬ìš© ë£¨í‹´ì—ëŠ” í¬í•¨í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.

    # âœ… ë³‘í•© ì¶”ë¡  (ë‹¨ì¼ ì´ë¯¸ì§€)
    def unified_predict_pipeline(original_weights="runs/detect/nunu_elna_exp1/weights/best.pt",
                                 finetuned_weights="runs/fine_tune/player_dot_finetune/weights/best.pt",
                                 source="sample.jpg",
                                 conf_orig=0.18, conf_fine=0.16):
        yolo_orig = YOLO(original_weights)
        yolo_fine = YOLO(finetuned_weights)

        result_orig = yolo_orig.predict(source=source, conf=conf_orig, save=False)[0]
        result_fine = yolo_fine.predict(source=source, conf=conf_fine, save=False)[0]

        merged_boxes = result_orig.boxes.data.tolist() + result_fine.boxes.data.tolist()
        print(f"[ğŸ”€] ê°ì²´ ì´ {len(merged_boxes)}ê°œ ë³‘í•©ë¨ (orig: {len(result_orig.boxes)}, fine: {len(result_fine.boxes)})")
        return merged_boxes


    # âœ… ë³‘í•© ë‹¤ì¤‘ ì´ë¯¸ì§€ ì¶”ë¡ 
    def unified_multiple_image_predict(
            folder="predict_images",
            original_weights="runs/detect/nunu_elna_exp1/weights/best.pt",
            finetuned_weights="runs/fine_tune/player_dot_finetune/weights/best.pt",
            conf_orig=0.18,
            conf_fine=0.16,
            tag="merged"
    ):
        yolo_orig = YOLO(original_weights)
        yolo_fine = YOLO(finetuned_weights)
        image_list = glob.glob(f"{folder}/*.jpg") + glob.glob(f"{folder}/*.png")

        for img_path in image_list:
            result_orig = yolo_orig.predict(source=img_path, conf=conf_orig, save=False)[0]
            result_fine = yolo_fine.predict(source=img_path, conf=conf_fine, save=False)[0]

            merged_boxes = result_orig.boxes.data.tolist() + result_fine.boxes.data.tolist()
            print(f"[ğŸ”€] {img_path} ê°ì²´ ì´ {len(merged_boxes)}ê°œ ë³‘í•©ë¨")


    def real_time_capture_predict(weights_path="runs/detect/nunu_elna_exp1/weights/best.pt",
                                  conf_thres=0.18):
        model = YOLO(weights_path)
        camera = dxcam.create(output_color="BGR")
        camera.start(target_fps=10)

        region = (0, 0, 1280, 720)  # QHD ì¢Œì¸¡ ìƒë‹¨ 1/4

        while True:
            frame = camera.get_latest_frame(region=region)
            if frame is None:
                continue

            results = model.predict(
                source=frame,
                conf=conf_thres,
                save_crop=True,
                save=False,
                show=False
            )

            for box in results[0].boxes.data:
                cls = int(box[5])
                if model.names[cls] == "projectile_attack":
                    print("[ğŸ¯] ê³µê²© ê°ì§€ë¨!")

            time.sleep(0.5)
